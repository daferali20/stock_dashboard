import streamlit as st
import yfinance as yf
from datetime import datetime, timedelta
import logging
import pandas as pd
import plotly.graph_objects as go
import sys
from dotenv import load_dotenv
import os
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©
# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
ALPHA_VANTAGE_API_KEY = os.getenv("ALPHA_VANTAGE_API_KEY")
if not ALPHA_VANTAGE_API_KEY:
    st.warning("âš ï¸ Ù…ÙØªØ§Ø­ ALPHA_VANTAGE_API_KEY ØºÙŠØ± Ù…Ø¹Ø±Ù ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©.")
# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
from components.indices import get_all_indices_data
from components.news import get_financial_news
from components.stock_news import get_stock_news
from components.gainers_losers import get_top_gainers, get_top_losers, get_most_active
from components.prediction import prepare_data_for_prediction, train_prediction_model, predict_next_day
from components.watchlist import load_watchlist_from_text, load_watchlist_from_file, fetch_watchlist_data
from components.performance import compare_with_index
from components.analysts import get_analyst_recommendations
from components.impact_stocks import show_impact_stocks
# ØªØ­Ø¯ÙŠØ¯ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø­Ø³Ø¨ Ø§Ù„Ø¥ØµØ¯Ø§Ø±

if st.__version__ >= "1.18.0":
    cache_decorator = st.cache_data
else:
    cache_decorator = st.cache(allow_output_mutation=True, suppress_st_warning=True)
#-------------------------------------
@cache_decorator(ttl=3600)
def load_index_data(symbol, start, end):
    """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø± Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù…Ø¯Ø© Ø³Ø§Ø¹Ø©"""
    return yf.download(symbol, start=start, end=end, auto_adjust=False, progress=False)

@cache_decorator(ttl=3600)
def load_stock_data(ticker, start, end):
    """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù‡Ù… Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù…Ø¯Ø© Ø³Ø§Ø¹Ø©"""
    return yf.download(ticker, start=start, end=end, auto_adjust=True, progress=False)
#-------------------------------------

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="ğŸ“Š Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©", layout="wide")
st.title("ğŸ“Š Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø©
start_date = st.sidebar.date_input("ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©", datetime.now() - timedelta(days=180))
end_date = st.sidebar.date_input("ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©", datetime.now())

# ØªØ¹Ø±ÙŠÙ ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ  Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø³ÙˆÙ‚", "ğŸ“ˆ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù…Ø¤Ø«Ø±Ø©", "ğŸ“‹ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©", "ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤", "ğŸ“° Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"
])

# ØªØ¨ÙˆÙŠØ¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
with tab1:
    st.subheader("ğŸ“Š Ø£Ø¯Ø§Ø¡ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø³ÙˆÙ‚")

    indices = {
        "S&P 500": "^GSPC",
        "Dow Jones": "^DJI", 
        "Nasdaq": "^IXIC"
    }

    for name, symbol in indices.items():
        try:
            df = load_index_data(symbol, start_date, end_date)

            if not df.empty and 'Close' in df.columns:
                close_series = df['Close'].copy()

                if not close_series.empty:
                    latest_value = close_series.iloc[-1]

                    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø±Ù‚Ù…ÙŠØ©
                    try:
                        latest_value = float(latest_value)
                    except ValueError:
                        st.warning(f"âš ï¸ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ù„Ù…Ø¤Ø´Ø± {name} ØºÙŠØ± Ø±Ù‚Ù…ÙŠØ©: {latest_value}")
                        continue

                    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØºÙŠØ± Ø§Ù„Ù…Ø¦ÙˆÙŠ
                    delta_pct = ""
                    if len(close_series) > 1:
                        prev_value = close_series.iloc[-2]
                        try:
                            prev_value = float(prev_value)
                            change = ((latest_value - prev_value) / prev_value) * 100
                            delta_pct = f"{change:.2f}%"
                        except Exception:
                            delta_pct = "N/A"

                    # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        st.metric(
                            label=name,
                            value=f"{latest_value:,.2f}",
                            delta=delta_pct
                        )
                    with col2:
                        st.line_chart(close_series)

                else:
                    st.warning(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ù„Ù„Ù…Ø¤Ø´Ø± {name}")
            else:
                st.warning(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù„Ù…Ø¤Ø´Ø± {name}")

        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {name}: {str(e)}")
            # Ø¥Ø°Ø§ Ø¹Ù†Ø¯Ùƒ logger Ù…ÙØ¹Ù‘Ù„
            try:
                logger.error(f"Error fetching {name} data: {str(e)}", exc_info=True)
            except:
                pass


# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù…Ø¤Ø«Ø±Ø©
with tab2:
    show_impact_stocks()
    

# ØªØ¨ÙˆÙŠØ¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©
with tab3:
    st.subheader("ğŸ“‹ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©")
    method = st.radio("Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„:", ["Ù†Øµ ÙŠØ¯ÙˆÙŠ", "ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù CSV"])
    symbols = []

    if method == "Ù†Øµ ÙŠØ¯ÙˆÙŠ":
        text = st.text_area("Ø£Ø¯Ø®Ù„ Ø±Ù…ÙˆØ² Ø§Ù„Ø£Ø³Ù‡Ù… (ÙƒÙ„ Ø±Ù…Ø² ÙÙŠ Ø³Ø·Ø±)")
        symbols = load_watchlist_from_text(text)
    else:
        file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'symbol'")
        if file:
            symbols = load_watchlist_from_file(file)

    if symbols:
        st.success(f"ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ {len(symbols)} Ø³Ù‡Ù….")
        data = fetch_watchlist_data(symbols, start_date, end_date)
        for symbol, df in data.items():
            st.write(f"ğŸ”¹ {symbol}")
            st.line_chart(df['close'])

# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù…ÙˆØ¯ Ø¨Ø§Ø³Ù… ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù„Ø§Ø­Ù‚Ø© Ø±Ù…Ø² Ø§Ù„Ø³Ù‡Ù… Ù…Ø«Ù„ close_aapl
def get_column_by_suffix(df, col_suffix, ticker):
    """
    ÙŠØ¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ù€ _<ticker> Ù…Ø«Ù„ 'close_aapl'
    """
    target = f"{col_suffix}_{ticker.lower()}"
    for col in df.columns:
        if col.lower() == target:
            return df[col]
    raise ValueError(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙˆØ¯: {target}")

# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØªÙ†Ø¨Ø¤
with tab4:
    st.subheader("ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø³Ù‡Ù…")
    ticker = st.text_input("Ø±Ù…Ø² Ø§Ù„Ø³Ù‡Ù…", "AAPL").upper()
    
    if ticker:
        try:
            data = load_stock_data(ticker, start_date, end_date)
            
            if not data.empty:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© MultiIndex Ø£Ùˆ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                if isinstance(data.columns, pd.MultiIndex):
                    data.columns = ['_'.join(col).strip().lower() for col in data.columns.values]
                else:
                    data.columns = data.columns.str.lower()

                with st.spinner('Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...'):
                    try:
                        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ 'close_<ticker>'
                        try:
                            close_series = get_column_by_suffix(data, 'close', ticker)
                        except Exception as e:
                            st.error(str(e))
                            st.text(f"ğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø©: {data.columns.tolist()}")
                            st.stop()
                        
                        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
                        data['sma_20'] = close_series.rolling(20).mean()
                        
                        delta = close_series.diff()
                        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
                        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
                        rs = gain / loss
                        data['rsi'] = 100 - (100 / (1 + rs))

                        # Ø§Ù„ØªÙ†Ø¨Ø¤
                        features, target = prepare_data_for_prediction(data)
                        model, mse = train_prediction_model(features, target)
                        
                        if model:
                            st.success(f"ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤: {mse:.4f})")
                            last_data = data.iloc[-1]
                            pred_price = predict_next_day(model, last_data)
                            current_price = float(close_series.iloc[-1])
                            change_pct = ((pred_price - current_price) / current_price) * 100
                            
                            col1, col2 = st.columns(2)
                            col1.metric("Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ", f"{current_price:.2f}")
                            col2.metric("Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ù„ØºØ¯", f"{pred_price:.2f}", 
                                        delta=f"{change_pct:.2f}%",
                                        delta_color="inverse" if change_pct < 0 else "normal")
                            
                            st.info("""
                            **ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬:**
                            - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†Ø³Ø¨Ø© Ù…ÙˆØ¬Ø¨Ø©: ØªØ´ÙŠØ± Ø¥Ù„Ù‰ ØµØ¹ÙˆØ¯ Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø³Ø¹Ø±
                            - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†Ø³Ø¨Ø© Ø³Ø§Ù„Ø¨Ø©: ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù‡Ø¨ÙˆØ· Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø³Ø¹Ø±
                            """)
                    
                    except Exception as e:
                        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
                        st.text(f"ğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø©: {data.columns.tolist()}")
                        logger.error(f"Analysis error: {str(e)} | Columns: {data.columns.tolist()}")

                # Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ S&P 500
                st.subheader("ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ù…Ø¤Ø´Ø± Ø§Ù„Ø³ÙˆÙ‚")
                try:
                    sp500 = load_index_data("^GSPC", start_date, end_date)
                    if not sp500.empty:
                        sp500.columns = sp500.columns.str.lower()

                        if 'close' not in sp500.columns:
                            st.warning("âš ï¸ Ù…Ø¤Ø´Ø± S&P 500 Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'close'")
                            st.text(f"ğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø©: {sp500.columns.tolist()}")
                            st.stop()

                        sp500_close = sp500['close'].copy()
                        data_close = close_series.copy()
                        
                        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                        norm_data = (data_close / data_close.iloc[0] * 100)
                        norm_sp500 = (sp500_close / sp500_close.iloc[0] * 100)
                        
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(
                            x=norm_data.index,
                            y=norm_data,
                            name=ticker,
                            line=dict(color='royalblue', width=2)
                        ))
                        fig.add_trace(go.Scatter(
                            x=norm_sp500.index,
                            y=norm_sp500,
                            name="S&P 500",
                            line=dict(color='gray', width=2)
                        ))
                        fig.update_layout(
                            title="Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ù‡Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù…Ø¤Ø´Ø± S&P 500",
                            yaxis_title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© Ù„Ù„ØªØºÙŠØ±",
                            hovermode="x unified"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                except Exception as e:
                    st.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}")
#----------------------99999999999--------------                    
def fetch_analyst_recommendations(ticker):
    if ALPHA_VANTAGE_API_KEY is None:
        st.error("âš ï¸ Ù…ÙØªØ§Ø­ Alpha Vantage ØºÙŠØ± Ù…Ø¹Ø±ÙØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª.")
        return None
# Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ (Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· ÙˆØ§Ù„Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ±Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©)
    url = f"https://www.alphavantage.co/query?function=ANALYST_RECOMMENDATION&symbol={ticker}&apikey={ALPHA_VANTAGE_API_KEY}"
    response = requests.get(url)
    if response.status_code == 200:
        return response.json()  # Ø£Ùˆ Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ØµÙŠØºØ©
    else:
        st.error(f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {response.status_code}")
        return None
                # ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø­Ù„Ù„ÙŠÙ†
                st.subheader("ğŸ§  ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø­Ù„Ù„ÙŠÙ†")
                try:
                    recs = get_analyst_recommendations(ticker)
                    if recs is not None and not recs.empty:
                        st.dataframe(
                            recs.style
                            .highlight_max(subset=['to grade'], color='lightgreen')
                            .set_properties(**{'text-align': 'right'})
                            .format({'to grade': '{:.1f}'})
                        )
                    else:
                        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ§Øª Ù…ØªØ§Ø­Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ù‡Ù…")
                except Exception as e:
                    st.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {str(e)}")
                    
        except Exception as e:
            st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¬Ø³ÙŠÙ…: {str(e)}")
            logger.error(f"Critical error in prediction tab: {str(e)}", exc_info=True)

# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
with tab5:
    st.subheader("ğŸ“° Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©")
    news = get_financial_news()
    for article in news[:5]:
        st.markdown(f"**{article['title']}**  \n{article['source']['name']} - {article['publishedAt'][:10]}")
        st.write(article['description'])

    st.subheader("ğŸ“° Ø£Ø®Ø¨Ø§Ø± Ø³Ù‡Ù… Ù…Ø¹ÙŠÙ†")
    ticker_news = st.text_input("Ø±Ù…Ø² Ø§Ù„Ø³Ù‡Ù… Ù„Ù„Ø£Ø®Ø¨Ø§Ø±", "MSFT").upper()
    if ticker_news:
        stock_news = get_stock_news(ticker_news)
        for article in stock_news[:5]:
            st.markdown(f"**{article['title']}**  \n{article['source']['name']} - {article['publishedAt'][:10]}")
            st.write(article['description'])
